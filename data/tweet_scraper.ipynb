{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.19.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.1)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (0.25.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (2024.2.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (4.10.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (3.6)\n",
      "Requirement already satisfied: outcome in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.16.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.22)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from webdriver-manager) (2.31.0)\n",
      "Collecting python-dotenv (from webdriver-manager)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\oscac\\appdata\\roaming\\python\\python312\\site-packages (from webdriver-manager) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver-manager) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver-manager) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver-manager) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver-manager) (2024.2.2)\n",
      "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv, webdriver-manager\n",
      "Successfully installed python-dotenv-1.0.1 webdriver-manager-4.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install selenium\n",
    "%pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from datetime import datetime, timedelta\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credenciales de Twitter\n",
    "USERNAME = 'ScrapeoUPM'\n",
    "PASSWORD = 'scrapeafutbol'\n",
    "EMAIL = 'oscar.marin@alumnos.upm.es'\n",
    "\n",
    "SCROLL_PAUSE_TIME = 3  # Tiempo de espera para que carguen nuevos tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login(driver, username, email, password):\n",
    "    \n",
    "    # Navegar a la página de inicio de sesión de Twitter\n",
    "    driver.get('https://twitter.com/login')\n",
    "    time.sleep(7)  # Esperar a que cargue la página\n",
    "\n",
    "    # Buscar el campo del nombre de usuario e ingresar el nombre de usuario o correo\n",
    "    username_input = driver.find_element(By.NAME, 'text')\n",
    "    username_input.send_keys(username)\n",
    "    username_input.send_keys(Keys.RETURN) #Presionar tecla enter\n",
    "    time.sleep(2)\n",
    "    \n",
    "    try:\n",
    "        # Buscar el campo de confirmación de correo\n",
    "        email_input = driver.find_element(By.NAME, 'text')\n",
    "        email_input.send_keys(email)\n",
    "        email_input.send_keys(Keys.RETURN)\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Buscar el campo de contraseña e ingresar la contraseña\n",
    "    password_input = driver.find_element(By.NAME, 'password')\n",
    "    password_input.send_keys(password)\n",
    "    password_input.send_keys(Keys.RETURN)\n",
    "    time.sleep(5)\n",
    "\n",
    "def scrap_n_tweets(driver, n_tweets: int, word_search: str, date_range: tuple):\n",
    "\n",
    "    word_link = word_search.replace(' ', '%20')\n",
    "    date_range = f'%20until%3A{date_range[1]}%20since%3A{date_range[0]}'\n",
    "\n",
    "    # Navegar a la página de búsqueda de Twitter\n",
    "    driver.get(f'https://twitter.com/search?q={word_link}{date_range}')\n",
    "    time.sleep(5)  # Esperar a que cargue la página\n",
    "\n",
    "    n = 0\n",
    "    tweets = []\n",
    "    while n < n_tweets:\n",
    "        # Extraer los tweets visibles en este momento\n",
    "        new_tweets = driver.find_elements(By.CSS_SELECTOR, 'article[data-testid=\"tweet\"]')\n",
    "        \n",
    "        # Imprimir el texto de los tweets extraídos\n",
    "        for tweet in new_tweets:\n",
    "            tweet_text = tweet.find_element(By.CSS_SELECTOR, 'div[data-testid=\"tweetText\"]')\n",
    "            tweet_date = tweet.find_element(By.CSS_SELECTOR, 'time').get_attribute('datetime')\n",
    "            tweet_lang  = tweet.find_element(By.CSS_SELECTOR, 'div[data-testid=\"tweetText\"]').get_attribute('lang')\n",
    "            tweets.append([word_search, tweet_text.text, tweet_date, tweet_lang])\n",
    "            n += 1\n",
    "            if n == n_tweets:\n",
    "                break\n",
    "\n",
    "        # Hacer scroll hasta el final de la página\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "    return tweets\n",
    "\n",
    "def scrap_all_tweets(driver, word_search: str, date_range: tuple):\n",
    "    \n",
    "    word_link = word_search.replace(' ', '%20')\n",
    "    date_range = f'%20until%3A{date_range[1]}%20since%3A{date_range[0]}'\n",
    "\n",
    "    # Navegar a la página de búsqueda de Twitter\n",
    "    driver.get(f'https://twitter.com/search?q={word_link}{date_range}+-filter%3Areplies&src=typed_query&f=top')\n",
    "    time.sleep(5)  # Esperar a que cargue la página\n",
    "  \n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    tweets = []\n",
    "    while True:\n",
    "        # Extraer los tweets visibles en este momento\n",
    "        new_tweets = driver.find_elements(By.CSS_SELECTOR, 'article[data-testid=\"tweet\"]')\n",
    "        \n",
    "        # Imprimir el texto de los tweets extraídos\n",
    "        for tweet in new_tweets:\n",
    "            tweet_text = tweet.find_element(By.CSS_SELECTOR, 'div[data-testid=\"tweetText\"]')\n",
    "            tweet_date = tweet.find_element(By.CSS_SELECTOR, 'time').get_attribute('datetime')\n",
    "            tweet_lang  = tweet.find_element(By.CSS_SELECTOR, 'div[data-testid=\"tweetText\"]').get_attribute('lang')\n",
    "            tweets.append([word_search, tweet_text.text, tweet_date, tweet_lang])\n",
    "            \n",
    "        # Hacer scroll hasta el final de la página\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2024-09-30', '2024-10-06'),\n",
       " ('2024-10-07', '2024-10-13'),\n",
       " ('2024-10-14', '2024-10-20'),\n",
       " ('2024-10-21', '2024-10-27'),\n",
       " ('2024-10-28', '2024-11-03'),\n",
       " ('2024-11-04', '2024-11-06')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_weeks(since, until):\n",
    "    weeks = []\n",
    "    actual_date = datetime.strptime(since, '%Y-%m-%d')\n",
    "    final_date = datetime.strptime(until, '%Y-%m-%d')\n",
    "\n",
    "    while actual_date + timedelta(days=7) < final_date:\n",
    "        # Definir el rango de cada semana\n",
    "        week_end = actual_date + timedelta(days=6) # Día actual + 6 días = 7 días\n",
    "\n",
    "        weeks.append((actual_date.strftime('%Y-%m-%d'), week_end.strftime('%Y-%m-%d')))\n",
    "        # Avanzar a la siguiente semana\n",
    "        actual_date = week_end + timedelta(days=1) # Empieza el siguiente día para no repetir\n",
    "\n",
    "    weeks.append((actual_date.strftime('%Y-%m-%d'), until))\n",
    "    return weeks\n",
    "\n",
    "get_weeks('2024-09-30', '2024-11-06')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data, filename):\n",
    "    with open(filename, 'a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file, delimiter=';')  \n",
    "        for row in data:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping tweets from 2023-08-01 to 2023-08-07\n",
      "Found 89 tweets\n",
      "Scraping tweets from 2023-08-08 to 2023-08-14\n",
      "Found 98 tweets\n",
      "Scraping tweets from 2023-08-15 to 2023-08-21\n",
      "Found 168 tweets\n",
      "Scraping tweets from 2023-08-22 to 2023-08-28\n",
      "Found 146 tweets\n",
      "Scraping tweets from 2023-08-29 to 2023-09-04\n",
      "Found 28 tweets\n",
      "Scraping tweets from 2023-09-05 to 2023-09-11\n",
      "Found 0 tweets\n",
      "5\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/raw/tweets/Ferran_Torres_tweets.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m i\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(checkpoint)\n\u001b[1;32m---> 29\u001b[0m \u001b[43msave_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_tweets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/raw/tweets/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mplayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_tweets.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m#driver.quit()\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m#time.sleep(30)\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# login(driver, USERNAME, EMAIL, PASSWORD)\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# tweets = scrap_all_tweets(driver, player, (since, until))\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m, in \u001b[0;36msave_data\u001b[1;34m(data, filename)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_data\u001b[39m(data, filename):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      3\u001b[0m         writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mwriter(file, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m)  \n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m data:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/raw/tweets/Ferran_Torres_tweets.csv'"
     ]
    }
   ],
   "source": [
    "player = 'Ferran Torres'\n",
    "since = '2023-08-01'\n",
    "until = '2024-07-15'\n",
    "n_tweets = 100\n",
    "\n",
    "chrome_options = Options()\n",
    "#chrome_options.add_argument(\"--headless\")  # Ejecuta Chrome en modo headless\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "login(driver, USERNAME, EMAIL, PASSWORD)\n",
    "\n",
    "weeks = get_weeks(since, until)\n",
    "\n",
    "# Crear un archivo CSV con las columnas correspondientes\n",
    "with open(f'raw/tweets/{player.replace(' ', '_')}_tweets.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file, delimiter=';')\n",
    "    writer.writerow(['player', 'text', 'date', 'lang'])\n",
    "\n",
    "# Iterar sobre las semanas y extraer los tweets\n",
    "all_tweets = []\n",
    "for i, (since, until) in enumerate(weeks):\n",
    "    print(f'Scraping tweets from {since} to {until}')\n",
    "    tweets = scrap_all_tweets(driver, player, (since, until))\n",
    "    print(f'Found {len(tweets)} tweets')\n",
    "    if len(tweets) == 0:\n",
    "        checkpoint = i\n",
    "        print(checkpoint)\n",
    "        save_data(all_tweets, f'raw/tweets/{player.replace(' ', '_')}_tweets.csv')\n",
    "        break\n",
    "        #driver.quit()\n",
    "        #time.sleep(30)\n",
    "        # driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "        # login(driver, USERNAME, EMAIL, PASSWORD)\n",
    "        # tweets = scrap_all_tweets(driver, player, (since, until))\n",
    "    \n",
    "    all_tweets.extend(tweets)\n",
    "    time.sleep(2)\n",
    "\n",
    "\n",
    "# Cerrar el navegador\n",
    "driver.quit()\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping tweets from 2023-09-26 to 2023-10-02\n",
      "Found 138 tweets\n",
      "Scraping tweets from 2023-10-03 to 2023-10-09\n",
      "Found 0 tweets\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "login(driver, USERNAME, EMAIL, PASSWORD)\n",
    "# Iterar sobre las semanas y extraer los tweets\n",
    "all_tweets = []\n",
    "for i, (since, until) in enumerate(weeks[8:]):\n",
    "    print(f'Scraping tweets from {since} to {until}')\n",
    "    tweets = scrap_all_tweets(driver, player, (since, until))\n",
    "    print(f'Found {len(tweets)} tweets')\n",
    "    if len(tweets) == 0:\n",
    "        checkpoint = i\n",
    "        print(checkpoint)\n",
    "        save_data(all_tweets, f'raw/tweets/{player.replace(' ', '_')}_tweets.csv')\n",
    "        break\n",
    "        #driver.quit()\n",
    "        #time.sleep(30)\n",
    "        # driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "        # login(driver, USERNAME, EMAIL, PASSWORD)\n",
    "        # tweets = scrap_all_tweets(driver, player, (since, until))\n",
    "    \n",
    "    all_tweets.extend(tweets)\n",
    "    time.sleep(2)\n",
    "\n",
    "\n",
    "# Cerrar el navegador\n",
    "driver.quit()\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2023-08-01', '2023-08-07'),\n",
       " ('2023-08-08', '2023-08-14'),\n",
       " ('2023-08-15', '2023-08-21'),\n",
       " ('2023-08-22', '2023-08-28'),\n",
       " ('2023-08-29', '2023-09-04'),\n",
       " ('2023-09-05', '2023-09-11'),\n",
       " ('2023-09-12', '2023-09-18'),\n",
       " ('2023-09-19', '2023-09-25'),\n",
       " ('2023-09-26', '2023-10-02'),\n",
       " ('2023-10-03', '2023-10-09'),\n",
       " ('2023-10-10', '2023-10-16'),\n",
       " ('2023-10-17', '2023-10-23'),\n",
       " ('2023-10-24', '2023-10-30'),\n",
       " ('2023-10-31', '2023-11-06'),\n",
       " ('2023-11-07', '2023-11-13'),\n",
       " ('2023-11-14', '2023-11-20'),\n",
       " ('2023-11-21', '2023-11-27'),\n",
       " ('2023-11-28', '2023-12-04'),\n",
       " ('2023-12-05', '2023-12-11'),\n",
       " ('2023-12-12', '2023-12-18'),\n",
       " ('2023-12-19', '2023-12-25'),\n",
       " ('2023-12-26', '2024-01-01'),\n",
       " ('2024-01-02', '2024-01-08'),\n",
       " ('2024-01-09', '2024-01-15'),\n",
       " ('2024-01-16', '2024-01-22'),\n",
       " ('2024-01-23', '2024-01-29'),\n",
       " ('2024-01-30', '2024-02-05'),\n",
       " ('2024-02-06', '2024-02-12'),\n",
       " ('2024-02-13', '2024-02-19'),\n",
       " ('2024-02-20', '2024-02-26'),\n",
       " ('2024-02-27', '2024-03-04'),\n",
       " ('2024-03-05', '2024-03-11'),\n",
       " ('2024-03-12', '2024-03-18'),\n",
       " ('2024-03-19', '2024-03-25'),\n",
       " ('2024-03-26', '2024-04-01'),\n",
       " ('2024-04-02', '2024-04-08'),\n",
       " ('2024-04-09', '2024-04-15'),\n",
       " ('2024-04-16', '2024-04-22'),\n",
       " ('2024-04-23', '2024-04-29'),\n",
       " ('2024-04-30', '2024-05-06'),\n",
       " ('2024-05-07', '2024-05-13'),\n",
       " ('2024-05-14', '2024-05-20'),\n",
       " ('2024-05-21', '2024-05-27'),\n",
       " ('2024-05-28', '2024-06-03'),\n",
       " ('2024-06-04', '2024-06-10'),\n",
       " ('2024-06-11', '2024-06-17'),\n",
       " ('2024-06-18', '2024-06-24'),\n",
       " ('2024-06-25', '2024-07-01'),\n",
       " ('2024-07-02', '2024-07-08'),\n",
       " ('2024-07-09', '2024-07-15')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'raw/tweets/{player.replace(' ', '_')}_tweets.csv', 'a', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file, delimiter=';')\n",
    "    #writer.writerow(['player', 'text', 'date', 'lang'])\n",
    "    for tweet in all_tweets:\n",
    "        writer.writerow(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "529"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ferran Torres</td>\n",
       "      <td>between jana, pina and bruna also being so you...</td>\n",
       "      <td>2023-08-01T21:01:13.000Z</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ferran Torres</td>\n",
       "      <td>So… you’ve met Freminet’s friend Pers</td>\n",
       "      <td>2023-08-04T16:53:31.000Z</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ferran Torres</td>\n",
       "      <td>ANDREW FARRELL SENDS THE \\n@NEREVOLUTION\\n INT...</td>\n",
       "      <td>2023-08-04T02:37:21.000Z</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ferran Torres</td>\n",
       "      <td>MAINSTREAM vs QUEEN OF ALT vs MEL-LOCAL  oh fe...</td>\n",
       "      <td>2023-08-01T02:31:46.000Z</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ferran Torres</td>\n",
       "      <td>Chin's Ig Post - Francine's favorite place !!...</td>\n",
       "      <td>2023-08-04T04:09:47.000Z</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>Ferran Torres</td>\n",
       "      <td>Ferran Torres must be a son to some top guy in...</td>\n",
       "      <td>2023-09-28T15:04:01.000Z</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>Ferran Torres</td>\n",
       "      <td>¡Cambio en el Barça!\\n\\nJoao Félix  Ferran Tor...</td>\n",
       "      <td>2023-09-29T20:31:37.000Z</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>Ferran Torres</td>\n",
       "      <td>Bruhhh  Ferran torres have more goal than  him...</td>\n",
       "      <td>2023-09-29T13:55:33.000Z</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>Ferran Torres</td>\n",
       "      <td>Min. 71 (0-0): Mueve el banquillo Xavi Hernánd...</td>\n",
       "      <td>2023-09-29T20:31:56.000Z</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>Ferran Torres</td>\n",
       "      <td>En directo, #BarçaSevillaFC (-)\\n\\nFerrán Tor...</td>\n",
       "      <td>2023-09-29T20:31:39.000Z</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1126 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             player                                               text  \\\n",
       "0     Ferran Torres  between jana, pina and bruna also being so you...   \n",
       "1     Ferran Torres             So… you’ve met Freminet’s friend Pers    \n",
       "2     Ferran Torres  ANDREW FARRELL SENDS THE \\n@NEREVOLUTION\\n INT...   \n",
       "3     Ferran Torres  MAINSTREAM vs QUEEN OF ALT vs MEL-LOCAL  oh fe...   \n",
       "4     Ferran Torres   Chin's Ig Post - Francine's favorite place !!...   \n",
       "...             ...                                                ...   \n",
       "1121  Ferran Torres  Ferran Torres must be a son to some top guy in...   \n",
       "1122  Ferran Torres  ¡Cambio en el Barça!\\n\\nJoao Félix  Ferran Tor...   \n",
       "1123  Ferran Torres  Bruhhh  Ferran torres have more goal than  him...   \n",
       "1124  Ferran Torres  Min. 71 (0-0): Mueve el banquillo Xavi Hernánd...   \n",
       "1125  Ferran Torres   En directo, #BarçaSevillaFC (-)\\n\\nFerrán Tor...   \n",
       "\n",
       "                          date lang  \n",
       "0     2023-08-01T21:01:13.000Z   en  \n",
       "1     2023-08-04T16:53:31.000Z   en  \n",
       "2     2023-08-04T02:37:21.000Z   en  \n",
       "3     2023-08-01T02:31:46.000Z   en  \n",
       "4     2023-08-04T04:09:47.000Z   en  \n",
       "...                        ...  ...  \n",
       "1121  2023-09-28T15:04:01.000Z   en  \n",
       "1122  2023-09-29T20:31:37.000Z   es  \n",
       "1123  2023-09-29T13:55:33.000Z   en  \n",
       "1124  2023-09-29T20:31:56.000Z   es  \n",
       "1125  2023-09-29T20:31:39.000Z   es  \n",
       "\n",
       "[1126 rows x 4 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(f'raw/tweets/{player.replace(' ', '_')}_tweets.csv', delimiter=';')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
