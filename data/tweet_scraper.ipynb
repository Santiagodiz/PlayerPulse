{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\santi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.25.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\santi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\santi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\santi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\santi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\santi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (4.9.0)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\santi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\santi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (23.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\santi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\santi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\santi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\santi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\santi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (1.16.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\santi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\santi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\santi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\santi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\santi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from webdriver-manager) (2.31.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\santi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from webdriver-manager) (1.0.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\santi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from webdriver-manager) (23.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\santi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->webdriver-manager) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\santi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->webdriver-manager) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\santi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->webdriver-manager) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\santi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->webdriver-manager) (2023.7.22)\n",
      "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Installing collected packages: webdriver-manager\n",
      "Successfully installed webdriver-manager-4.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install selenium\n",
    "%pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from datetime import datetime, timedelta\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credenciales de Twitter\n",
    "USERNAME = 'ScrapeoUPM'\n",
    "PASSWORD = 'scrapeafutbol'\n",
    "EMAIL = 'oscar.marin@alumnos.upm.es'\n",
    "\n",
    "SCROLL_PAUSE_TIME = 5  # Tiempo de espera para que carguen nuevos tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login(driver, username, email, password):\n",
    "    \n",
    "    # Navegar a la página de inicio de sesión de Twitter\n",
    "    driver.get('https://twitter.com/login')\n",
    "    time.sleep(7)  # Esperar a que cargue la página\n",
    "\n",
    "    # Buscar el campo del nombre de usuario e ingresar el nombre de usuario o correo\n",
    "    username_input = driver.find_element(By.NAME, 'text')\n",
    "    username_input.send_keys(username)\n",
    "    username_input.send_keys(Keys.RETURN) #Presionar tecla enter\n",
    "    time.sleep(2)\n",
    "    \n",
    "    try:\n",
    "        # Buscar el campo de confirmación de correo\n",
    "        email_input = driver.find_element(By.NAME, 'text')\n",
    "        email_input.send_keys(email)\n",
    "        email_input.send_keys(Keys.RETURN)\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Buscar el campo de contraseña e ingresar la contraseña\n",
    "    password_input = driver.find_element(By.NAME, 'password')\n",
    "    password_input.send_keys(password)\n",
    "    password_input.send_keys(Keys.RETURN)\n",
    "    time.sleep(5)\n",
    "\n",
    "def scrap_n_tweets(driver, n_tweets: int, word_search: str, date_range: tuple):\n",
    "\n",
    "    word_link = word_search.replace(' ', '%20')\n",
    "    date_range = f'%20until%3A{date_range[1]}%20since%3A{date_range[0]}'\n",
    "\n",
    "    # Navegar a la página de búsqueda de Twitter\n",
    "    driver.get(f'https://twitter.com/search?q={word_link}{date_range}')\n",
    "    time.sleep(5)  # Esperar a que cargue la página\n",
    "\n",
    "    n = 0\n",
    "    tweets = []\n",
    "    while n < n_tweets:\n",
    "        # Extraer los tweets visibles en este momento\n",
    "        new_tweets = driver.find_elements(By.CSS_SELECTOR, 'article[data-testid=\"tweet\"]')\n",
    "        \n",
    "        # Imprimir el texto de los tweets extraídos\n",
    "        for tweet in new_tweets:\n",
    "            tweet_text = tweet.find_element(By.CSS_SELECTOR, 'div[data-testid=\"tweetText\"]')\n",
    "            tweet_date = tweet.find_element(By.CSS_SELECTOR, 'time').get_attribute('datetime')\n",
    "            tweet_lang  = tweet.find_element(By.CSS_SELECTOR, 'div[data-testid=\"tweetText\"]').get_attribute('lang')\n",
    "            tweets.append([word_search, tweet_text.text, tweet_date, tweet_lang])\n",
    "            n += 1\n",
    "            if n == n_tweets:\n",
    "                break\n",
    "\n",
    "        # Hacer scroll hasta el final de la página\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "    return tweets\n",
    "\n",
    "def scrap_all_tweets(driver, word_search: str, date_range: tuple):\n",
    "    \n",
    "    word_link = word_search.replace(' ', '%20')\n",
    "    date_range = f'%20until%3A{date_range[1]}%20since%3A{date_range[0]}'\n",
    "\n",
    "    # Navegar a la página de búsqueda de Twitter\n",
    "    driver.get(f'https://twitter.com/search?q={word_link}{date_range}+-filter%3Areplies&src=typed_query&f=top')\n",
    "    time.sleep(5)  # Esperar a que cargue la página\n",
    "  \n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    tweets = []\n",
    "    while True:\n",
    "        # Extraer los tweets visibles en este momento\n",
    "        new_tweets = driver.find_elements(By.CSS_SELECTOR, 'article[data-testid=\"tweet\"]')\n",
    "        \n",
    "        # Imprimir el texto de los tweets extraídos\n",
    "        for tweet in new_tweets:\n",
    "            tweet_text = tweet.find_element(By.CSS_SELECTOR, 'div[data-testid=\"tweetText\"]')\n",
    "            tweet_date = tweet.find_element(By.CSS_SELECTOR, 'time').get_attribute('datetime')\n",
    "            tweet_lang  = tweet.find_element(By.CSS_SELECTOR, 'div[data-testid=\"tweetText\"]').get_attribute('lang')\n",
    "            tweets.append([word_search, tweet_text.text, tweet_date, tweet_lang])\n",
    "            \n",
    "        # Hacer scroll hasta el final de la página\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "    \n",
    "    \n",
    "\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2024-09-30', '2024-10-06'),\n",
       " ('2024-10-07', '2024-10-13'),\n",
       " ('2024-10-14', '2024-10-20'),\n",
       " ('2024-10-21', '2024-10-27'),\n",
       " ('2024-10-28', '2024-11-03'),\n",
       " ('2024-11-04', '2024-11-06')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_weeks(since, until):\n",
    "    weeks = []\n",
    "    actual_date = datetime.strptime(since, '%Y-%m-%d')\n",
    "    final_date = datetime.strptime(until, '%Y-%m-%d')\n",
    "\n",
    "    while actual_date + timedelta(days=7) < final_date:\n",
    "        # Definir el rango de cada semana\n",
    "        week_end = actual_date + timedelta(days=6) # Día actual + 6 días = 7 días\n",
    "\n",
    "        weeks.append((actual_date.strftime('%Y-%m-%d'), week_end.strftime('%Y-%m-%d')))\n",
    "        # Avanzar a la siguiente semana\n",
    "        actual_date = week_end + timedelta(days=1) # Empieza el siguiente día para no repetir\n",
    "\n",
    "    weeks.append((actual_date.strftime('%Y-%m-%d'), until))\n",
    "    return weeks\n",
    "\n",
    "get_weeks('2024-09-30', '2024-11-06')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data, filename):\n",
    "    with open(filename, 'a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file, delimiter=';')  \n",
    "        for row in data:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: unmatched '(' (2623381166.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[9], line 18\u001b[1;36m\u001b[0m\n\u001b[1;33m    with open(f'raw/tweets/{player.replace(' ', '_')}_tweets.csv', 'w', newline='', encoding='utf-8') as file:\u001b[0m\n\u001b[1;37m                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m f-string: unmatched '('\n"
     ]
    }
   ],
   "source": [
    "# Si es la primera ejecución del jugador\n",
    "\n",
    "player = 'Ferran Torres'\n",
    "since = '2023-08-01'\n",
    "until = '2024-07-15'\n",
    "n_tweets = 100\n",
    "\n",
    "chrome_options = Options()\n",
    "#chrome_options.add_argument(\"--headless\")  # Ejecuta Chrome en modo headless\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "login(driver, USERNAME, EMAIL, PASSWORD)\n",
    "\n",
    "weeks = get_weeks(since, until)\n",
    "\n",
    "# Crear un archivo CSV con las columnas correspondientes\n",
    "with open(f'raw/tweets/{player.replace(' ', '_')}_tweets.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file, delimiter=';')\n",
    "    writer.writerow(['player', 'text', 'date', 'lang'])\n",
    "\n",
    "# Iterar sobre las semanas y extraer los tweets\n",
    "all_tweets = []\n",
    "for i, (since, until) in enumerate(weeks):\n",
    "    print(f'Scraping tweets from {since} to {until}')\n",
    "    tweets = scrap_all_tweets(driver, player, (since, until))\n",
    "    print(f'Found {len(tweets)} tweets')\n",
    "    if len(tweets) == 0:\n",
    "        print(f'Failed in recollection from {(since, until)}')\n",
    "        save_data(all_tweets, f'raw/tweets/{player.replace(' ', '_')}_tweets.csv')\n",
    "        break\n",
    "    \n",
    "    all_tweets.extend(tweets)\n",
    "    time.sleep(5)\n",
    "\n",
    "\n",
    "# Cerrar el navegador\n",
    "driver.quit()\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: unmatched '(' (3123321355.py, line 27)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[10], line 27\u001b[1;36m\u001b[0m\n\u001b[1;33m    save_data(all_tweets, f'raw/tweets/{player.replace(' ', '_')}_tweets.csv')\u001b[0m\n\u001b[1;37m                                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m f-string: unmatched '('\n"
     ]
    }
   ],
   "source": [
    "# Si quieres reanudar con un jugador que ya tiene tweets recopilados\n",
    "\n",
    "player = 'Ferran Torres'\n",
    "since = '2023-08-01'\n",
    "until = '2024-07-15'\n",
    "n_tweets = 100\n",
    "\n",
    "chrome_options = Options()\n",
    "#chrome_options.add_argument(\"--headless\")  # Ejecuta Chrome en modo headless\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "login(driver, USERNAME, EMAIL, PASSWORD)\n",
    "\n",
    "weeks = get_weeks(since, until)\n",
    "# Ver en qué semana se quedó\n",
    "ini = weeks.index(('2024-01-30', '2024-02-05')) # Poner manualmente\n",
    "\n",
    "# Iterar sobre las semanas y extraer los tweets\n",
    "all_tweets = []\n",
    "for i, (since, until) in enumerate(weeks[ini:]):\n",
    "    print(f'Scraping tweets from {since} to {until}')\n",
    "    tweets = scrap_all_tweets(driver, player, (since, until))\n",
    "    print(f'Found {len(tweets)} tweets')\n",
    "    if len(tweets) == 0:\n",
    "        print(f'Failed in recollection from {(since, until)}')\n",
    "        save_data(all_tweets, f'raw/tweets/{player.replace(' ', '_')}_tweets.csv')\n",
    "        break\n",
    "    \n",
    "    all_tweets.extend(tweets)\n",
    "    time.sleep(5)\n",
    "\n",
    "\n",
    "# Cerrar el navegador\n",
    "driver.quit()\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2023-08-01', '2023-08-07'),\n",
       " ('2023-08-08', '2023-08-14'),\n",
       " ('2023-08-15', '2023-08-21'),\n",
       " ('2023-08-22', '2023-08-28'),\n",
       " ('2023-08-29', '2023-09-04'),\n",
       " ('2023-09-05', '2023-09-11'),\n",
       " ('2023-09-12', '2023-09-18'),\n",
       " ('2023-09-19', '2023-09-25'),\n",
       " ('2023-09-26', '2023-10-02'),\n",
       " ('2023-10-03', '2023-10-09'),\n",
       " ('2023-10-10', '2023-10-16'),\n",
       " ('2023-10-17', '2023-10-23'),\n",
       " ('2023-10-24', '2023-10-30'),\n",
       " ('2023-10-31', '2023-11-06'),\n",
       " ('2023-11-07', '2023-11-13'),\n",
       " ('2023-11-14', '2023-11-20'),\n",
       " ('2023-11-21', '2023-11-27'),\n",
       " ('2023-11-28', '2023-12-04'),\n",
       " ('2023-12-05', '2023-12-11'),\n",
       " ('2023-12-12', '2023-12-18'),\n",
       " ('2023-12-19', '2023-12-25'),\n",
       " ('2023-12-26', '2024-01-01'),\n",
       " ('2024-01-02', '2024-01-08'),\n",
       " ('2024-01-09', '2024-01-15'),\n",
       " ('2024-01-16', '2024-01-22'),\n",
       " ('2024-01-23', '2024-01-29'),\n",
       " ('2024-01-30', '2024-02-05'),\n",
       " ('2024-02-06', '2024-02-12'),\n",
       " ('2024-02-13', '2024-02-19'),\n",
       " ('2024-02-20', '2024-02-26'),\n",
       " ('2024-02-27', '2024-03-04'),\n",
       " ('2024-03-05', '2024-03-11'),\n",
       " ('2024-03-12', '2024-03-18'),\n",
       " ('2024-03-19', '2024-03-25'),\n",
       " ('2024-03-26', '2024-04-01'),\n",
       " ('2024-04-02', '2024-04-08'),\n",
       " ('2024-04-09', '2024-04-15'),\n",
       " ('2024-04-16', '2024-04-22'),\n",
       " ('2024-04-23', '2024-04-29'),\n",
       " ('2024-04-30', '2024-05-06'),\n",
       " ('2024-05-07', '2024-05-13'),\n",
       " ('2024-05-14', '2024-05-20'),\n",
       " ('2024-05-21', '2024-05-27'),\n",
       " ('2024-05-28', '2024-06-03'),\n",
       " ('2024-06-04', '2024-06-10'),\n",
       " ('2024-06-11', '2024-06-17'),\n",
       " ('2024-06-18', '2024-06-24'),\n",
       " ('2024-06-25', '2024-07-01'),\n",
       " ('2024-07-02', '2024-07-08'),\n",
       " ('2024-07-09', '2024-07-15')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ferran Torres</td>\n",
       "      <td>between jana, pina and bruna also being so you...</td>\n",
       "      <td>2023-08-01T21:01:13.000Z</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ferran Torres</td>\n",
       "      <td>So… you’ve met Freminet’s friend Pers</td>\n",
       "      <td>2023-08-04T16:53:31.000Z</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ferran Torres</td>\n",
       "      <td>ANDREW FARRELL SENDS THE \\r\\n@NEREVOLUTION\\r\\n...</td>\n",
       "      <td>2023-08-04T02:37:21.000Z</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ferran Torres</td>\n",
       "      <td>MAINSTREAM vs QUEEN OF ALT vs MEL-LOCAL  oh fe...</td>\n",
       "      <td>2023-08-01T02:31:46.000Z</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ferran Torres</td>\n",
       "      <td>Chin's Ig Post - Francine's favorite place !!...</td>\n",
       "      <td>2023-08-04T04:09:47.000Z</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3928</th>\n",
       "      <td>Ferran Torres</td>\n",
       "      <td>Ferran Torres misses his birthday 75% of all y...</td>\n",
       "      <td>2024-02-29T16:37:09.000Z</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3929</th>\n",
       "      <td>Ferran Torres</td>\n",
       "      <td>• Vinicius Jr a encvlé Ansu Fati\\n• Vinicius J...</td>\n",
       "      <td>2024-03-03T20:06:41.000Z</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3930</th>\n",
       "      <td>Ferran Torres</td>\n",
       "      <td>Empieza el entreno del Barça para preparar el ...</td>\n",
       "      <td>2024-03-02T10:15:25.000Z</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3931</th>\n",
       "      <td>Ferran Torres</td>\n",
       "      <td>mucho se habla de lamine pero poco de que tene...</td>\n",
       "      <td>2024-02-29T14:43:49.000Z</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3932</th>\n",
       "      <td>Ferran Torres</td>\n",
       "      <td>-El caso de Tito Berni.\\n-El caso Koldo.\\n-Otr...</td>\n",
       "      <td>2024-02-28T19:50:52.000Z</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3933 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             player                                               text  \\\n",
       "0     Ferran Torres  between jana, pina and bruna also being so you...   \n",
       "1     Ferran Torres             So… you’ve met Freminet’s friend Pers    \n",
       "2     Ferran Torres  ANDREW FARRELL SENDS THE \\r\\n@NEREVOLUTION\\r\\n...   \n",
       "3     Ferran Torres  MAINSTREAM vs QUEEN OF ALT vs MEL-LOCAL  oh fe...   \n",
       "4     Ferran Torres   Chin's Ig Post - Francine's favorite place !!...   \n",
       "...             ...                                                ...   \n",
       "3928  Ferran Torres  Ferran Torres misses his birthday 75% of all y...   \n",
       "3929  Ferran Torres  • Vinicius Jr a encvlé Ansu Fati\\n• Vinicius J...   \n",
       "3930  Ferran Torres  Empieza el entreno del Barça para preparar el ...   \n",
       "3931  Ferran Torres  mucho se habla de lamine pero poco de que tene...   \n",
       "3932  Ferran Torres  -El caso de Tito Berni.\\n-El caso Koldo.\\n-Otr...   \n",
       "\n",
       "                          date lang  \n",
       "0     2023-08-01T21:01:13.000Z   en  \n",
       "1     2023-08-04T16:53:31.000Z   en  \n",
       "2     2023-08-04T02:37:21.000Z   en  \n",
       "3     2023-08-01T02:31:46.000Z   en  \n",
       "4     2023-08-04T04:09:47.000Z   en  \n",
       "...                        ...  ...  \n",
       "3928  2024-02-29T16:37:09.000Z   en  \n",
       "3929  2024-03-03T20:06:41.000Z   fr  \n",
       "3930  2024-03-02T10:15:25.000Z   es  \n",
       "3931  2024-02-29T14:43:49.000Z   es  \n",
       "3932  2024-02-28T19:50:52.000Z   es  \n",
       "\n",
       "[3933 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(f'raw/tweets/{player.replace(' ', '_')}_tweets.csv', delimiter=';')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
