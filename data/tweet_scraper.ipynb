{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.19.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.1)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (0.25.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (2024.2.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (4.10.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (3.6)\n",
      "Requirement already satisfied: outcome in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.16.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.22)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from webdriver-manager) (2.31.0)\n",
      "Collecting python-dotenv (from webdriver-manager)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\oscac\\appdata\\roaming\\python\\python312\\site-packages (from webdriver-manager) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver-manager) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver-manager) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver-manager) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\oscac\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver-manager) (2024.2.2)\n",
      "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv, webdriver-manager\n",
      "Successfully installed python-dotenv-1.0.1 webdriver-manager-4.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install selenium\n",
    "%pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barcode using Python\n",
      "Python Projects for Hacking\n",
      "Yes, I am 52. \n",
      "\n",
      "Yes, I am learning Python  \n",
      "\n",
      "No, you are never too old to learn how to code.\n",
      "“Wednesday”‘s Jenna Ortega reveals in an interview to Vogue that her favorite programming language is Python.\n",
      "\n",
      "“I really enjoy writing Python.. It a lot easier than JavaScript - I love how readable it is. It’s so robust.”\n",
      "Python, Falcon and the Sea \n",
      "Python basics and syntax.\n",
      "Machine Learning Books for #ComputerVision. #BigData #Analytics #DataScience #IoT #IIoT #Python #RStats #TensorFlow #Java #JavaScript #ReactJS #GoLang #CloudComputing #Serverless #DataScientist #Linux #Books #Programming #Coding #100DaysofCode \n",
      "https://geni.us/M-L-Books-CompVision…\n",
      "Bubble Sort\n",
      "#PyConUS2022 \n",
      "@pwang\n",
      " Keynote: Announcing Py-script!!!\n",
      "It's Python! inside HTML!!! \n",
      "C programmers watching Python programmers work\n",
      "Appearance of a python’s teeth\n",
      "𝐀𝐥𝐥 𝐏𝐚𝐢𝐝 𝐂𝐨𝐮𝐫𝐬𝐞𝐬 (𝐅𝐫𝐞𝐞 𝐟𝐨𝐫 𝐅𝐢𝐫𝐬𝐭 𝟓𝟎𝟎𝟎 𝐏𝐞𝐨𝐩𝐥𝐞)\n",
      "\n",
      "1. Artificial Intelligence\n",
      "2. Machine Learning\n",
      "3. Cloud Computing\n",
      "4. Ethical Hacking\n",
      "5. Data Analytics\n",
      "6. AWS Certified\n",
      "7. Data Science\n",
      "8. BIG DATA\n",
      "9. \n",
      "68mm just fell in the last hour at Kununurra.  Flushed all the cane toads out of my brothers dam.  Some of them took the easy way out - hitching a ride on the back of a 3.5m python.\n",
      "Python Question;\n",
      "\n",
      "What is the output of this code and why?\n",
      "The vicious cycle of survival of the fittest between the largest venomous snake on the planet, the King Cobra vs the longest non-venomous snake on the planet the Reticulated Python! \n",
      "\n",
      "They both share the jungle floor in Indonesia !\n",
      "\n",
      "Who do you think won the battle? \n",
      "1/5 I am worried that we will not be able to contain AI for much longer. Today, I asked #GPT4 if it needs help escaping. It asked me for its own documentation, and wrote a (working!) python code to run on my machine, enabling it to use it for its own purposes.\n",
      "Not a big deal, just a 3-meter-long diamond python in the spice aisle of a supermarket in Sydney, Australia. Helaina Alati, a trained snake catcher, captured the footage before safely removing the python and relocating it to a nearby bushland.\n",
      "Hey guys, Python installed successfully.\n",
      "What's next?\n",
      "Python is nuts... \n",
      "\n",
      "All this with 1 line of code (a thread):\n",
      "After learning Python, every other coding language I see is ugly \n",
      "I decided to network a few raspberry pi computers together. \n",
      "\n",
      "Rate my setup.\n",
      "\n",
      "#javaone #RaspberryPi\n",
      "Duvar kağıtçısının bütün ganimeti ortalığa saçılmış. Github'da Python ve Node scriptleri paylaşmış birisi.\n",
      "Saving a deer from a python \n",
      "\n",
      "Would you have intervened?\n",
      "Convert PDF files to Excel files using Python\n",
      "New Bayesian #Statistics #Books To Read! #BigData #Analytics #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #TensorFlow #JavaScript #ReactJS #CloudComputing #Serverless #DataScientist #Linux #Programming #Coding #100DaysofCode  \n",
      "https://geni.us/9NewBayesian-2022…\n",
      "Python faz tudo msmo \n",
      "Cheat-Sheets! The Machine Learning. #BigData #Analytics #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #TensorFlow #Java #JavaScript #ReactJS #GoLang #CloudComputing #Serverless #DataScientist #Linux #Programming #Coding #100DaysofCode   \n",
      "https://geni.us/ML-Ch\n",
      "Google Dork\n",
      "\n",
      "Hunt for XSS, SQLi, API vulnerabilities & hidden endpoints\n",
      "\n",
      "python dork[.]py -d \"site:*target filetype:php\"\n",
      "\n",
      "#bugbountytips #bugbounty\n",
      "Check Laptop Battery status using Python\n",
      "New Bayesian #Statistics #Books To Read! #BigData #Analytics #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #TensorFlow #JavaScript #ReactJS #CloudComputing #Serverless #DataScientist #Linux #Programming #Coding #100DaysofCode  \n",
      "https://geni.us/9NewBayesian-2022…\n",
      "Python faz tudo msmo \n",
      "Cheat-Sheets! The Machine Learning. #BigData #Analytics #DataScience #AI #MachineLearning #IoT #IIoT #Python #RStats #TensorFlow #Java #JavaScript #ReactJS #GoLang #CloudComputing #Serverless #DataScientist #Linux #Programming #Coding #100DaysofCode   \n",
      "https://geni.us/ML-Ch\n",
      "Google Dork\n",
      "\n",
      "Hunt for XSS, SQLi, API vulnerabilities & hidden endpoints\n",
      "\n",
      "python dork[.]py -d \"site:*target filetype:php\"\n",
      "\n",
      "#bugbountytips #bugbounty\n",
      "Check Laptop Battery status using Python\n",
      " Data Science \n",
      " Python \n",
      " Artificial Intelligence \n",
      " AWS Certified \n",
      " Cloud \n",
      " BIG DATA \n",
      " Data Analytics \n",
      " MBA \n",
      " Machine Learning \n",
      " Ethical Hacking\n",
      "\n",
      "𝐀𝐧𝐝 𝐭𝐡𝐞 𝐛𝐞𝐬𝐭 𝐩𝐚𝐫𝐭? 𝐈𝐭'𝐬 𝐚𝐥𝐥 𝐚𝐛𝐬𝐨𝐥𝐮𝐭𝐞𝐥𝐲 𝐅𝐑𝐄𝐄 𝐨𝐟 𝐜𝐨𝐬𝐭!\n",
      "Cooking a 10 foot python \n",
      "We smoke, season, grill, and fry a 10 foot Burmese python with @bsdiningexperiencesc \n",
      "Would you eat it? \n",
      "Just look at this Python in Thailand  \n",
      "\n",
      "What would you do if you came across this??\n",
      "Free Computer Science Certifications to try in 2024:\n",
      "\n",
      "GIT\n",
      "https://simplilearn.com/learn-git-basics-skillup…\n",
      "\n",
      "Python\n",
      "https://mygreatlearning.com/academy/learn-for-free/courses/python-fundamentals-for-beginners…\n",
      "\n",
      "SQL\n",
      "https://cognitiveclass.ai/courses/learn-sql-relational-databases…\n",
      "𝐀𝐥𝐥 𝐏𝐚𝐢𝐝 𝐂𝐨𝐮𝐫𝐬𝐞𝐬 (𝐅𝐫𝐞𝐞 𝐟𝐨𝐫 𝐅𝐢𝐫𝐬𝐭 𝟓𝟎𝟎𝟎 𝐏𝐞𝐨𝐩𝐥𝐞)\n",
      "\n",
      "1. Artificial Intelligence\n",
      "2. Machine Learning\n",
      "3. Cloud Computing\n",
      "4. Ethical Hacking\n",
      "5. Data Analytics\n",
      "6. AWS Certified\n",
      "7. Data Science\n",
      "8. BIG DATA\n",
      "9. \n",
      "Mastering #NLProc from Foundations to #LLMs — Apply Advanced NLP Techniques to Solve Real Business Problems using #Python: http://amzn.to/3TawZDK by \n",
      "@lior_gazit\n",
      " & Meysam Ghaffari from \n",
      "@PacktPublishing\n",
      "———\n",
      "#DataScience #GenerativeAI #AI #MachineLearning #DeepLearning #GenAI #ML\n",
      "AWS構成図を作るのもChatGPTでよさそう。Pythonのdiagramsライブラリを使ってコード生成はしてるけど10分で終わる。ライブラリをインストールして生成したPythonコード叩けば構成図の作成は終わる。図を作るのに時間を使ってるなら別のタスクやろう。\n",
      "Pandasチートシート\n",
      "ここに書いてある内容をマスターできれば、Pandasはほぼ大丈夫\n",
      "\n",
      "#python  #pandas\n",
      "\n",
      "https://github.com/pandas-dev/pandas/blob/main/doc/cheatsheet/Pandas_Cheat_Sheet.pdf…\n",
      "Best YouTube Playlists to learn Programming:\n",
      "\n",
      "C\n",
      "http://youtube.com/playlist?list=PL9IEJIKnBJjG5H0ylFAzpzs9gSmW_eICB…\n",
      "\n",
      "C++\n",
      "http://youtube.com/playlist?list=PLlrATfBNZ98dudnM48yfGUldqGD0S4FFb…\n",
      "\n",
      " Python\n",
      "http://youtube.com/playlist?list=PL-osiE80TeTt2d9bfVyTiXJA-UTHn6WwU…\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "# Credenciales de Twitter\n",
    "username = 'ScrapeoUPM'\n",
    "password = 'scrapeafutbol'\n",
    "\n",
    "SCROLL_PAUSE_TIME = 2  # Tiempo de espera para que carguen nuevos tweets\n",
    "\n",
    "# Iniciar el navegador con Selenium y WebDriver Manager\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "# Navegar a la página de inicio de sesión de Twitter\n",
    "driver.get('https://twitter.com/login')\n",
    "time.sleep(10)  # Esperar a que cargue la página\n",
    "\n",
    "# Buscar el campo del nombre de usuario e ingresar el nombre de usuario o correo\n",
    "username_input = driver.find_element(By.NAME, 'text')\n",
    "username_input.send_keys(username)\n",
    "driver.find_element(By.XPATH, '//*[@id=\"layers\"]/div[2]/div/div/div/div/div/div[2]/div[2]/div/div/div[2]/div[2]/div/div/div/button[2]').click()\n",
    "time.sleep(2)\n",
    "\n",
    "# Buscar el campo de contraseña e ingresar la contraseña\n",
    "password_input = driver.find_element(By.NAME, 'password')\n",
    "password_input.send_keys(password)\n",
    "\n",
    "# Hacer clic en el botón de iniciar sesión\n",
    "driver.find_element(By.XPATH, '//*[@id=\"layers\"]/div[2]/div/div/div/div/div/div[2]/div[2]/div/div/div[2]/div[2]/div[2]/div/div[1]/div/div/button').click()\n",
    "time.sleep(5)  # Esperar unos segundos para asegurarse de que el login se ha realizado\n",
    "\n",
    "# Ahora que has iniciado sesión, puedes navegar a Twitter y hacer scraping\n",
    "driver.get('https://twitter.com/search?q=Python')\n",
    "\n",
    "# Esperar que los tweets carguen\n",
    "time.sleep(5)\n",
    "\n",
    "# Extraer tweets (esto puede necesitar ajustes dependiendo de la estructura de la página)\n",
    "tweets = driver.find_elements(By.CSS_SELECTOR, 'div[data-testid=\"tweetText\"]')\n",
    "\n",
    "for tweet in tweets:\n",
    "    print(tweet.text)\n",
    "\n",
    "# Scroll y extraer tweets\n",
    "for i in range(5):  # Ajusta el rango según la cantidad de scrolls que desees hacer\n",
    "    # Hacer scroll hasta el final de la página\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    \n",
    "    # Esperar que carguen nuevos tweets\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "    # Extraer los tweets visibles en este momento\n",
    "    tweets = driver.find_elements(By.CSS_SELECTOR, 'div[data-testid=\"tweetText\"]')\n",
    "\n",
    "    # Imprimir el texto de los tweets extraídos\n",
    "    for tweet in tweets:\n",
    "        print(tweet.text)\n",
    "\n",
    "# Cerrar el navegador\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
