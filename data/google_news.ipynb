{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, quote\n",
    "from lxml import etree\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import time\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import datetime\n",
    "from selenium.webdriver.edge.options import Options\n",
    "import pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_urls(jugador, anio_inicio, mes_inicio, dia_inicio, anio_fin, mes_fin, dia_fin):\n",
    "    # referencia https://news.google.com/search?q=nombre_jugador+de_futbol+after:YYYY-MM-DD+before:YYYY-MM-DD\n",
    "    \n",
    "    interval_tuples = []\n",
    "    \n",
    "    # se hacen intervalos de 1 semana\n",
    "    while True:\n",
    "        if anio_inicio == anio_fin and mes_inicio == mes_fin and dia_inicio >= dia_fin:\n",
    "            break\n",
    "\n",
    "        if anio_inicio == anio_fin and mes_inicio > mes_fin and dia_inicio:\n",
    "            break\n",
    "\n",
    "        if anio_inicio > anio_fin:\n",
    "            break\n",
    "        \n",
    "        interval_tuples.append((anio_inicio, mes_inicio, dia_inicio))\n",
    "        \n",
    "        dia_inicio += 7\n",
    "        \n",
    "        if dia_inicio > 30:\n",
    "            dia_inicio = 1\n",
    "            mes_inicio += 1\n",
    "        \n",
    "        if mes_inicio > 12:\n",
    "            mes_inicio = 1\n",
    "            anio_inicio += 1\n",
    "\n",
    "    print(interval_tuples)\n",
    "\n",
    "    urls = []\n",
    "\n",
    "    for interval in interval_tuples:\n",
    "        anio, mes, dia = interval\n",
    "\n",
    "        url = f\"https://news.google.com/search?q={jugador.replace(' ', '%20')}+after:{anio}-{mes}-{dia}+before:{anio}-{mes}-{dia + 7}\"\n",
    "        urls.append(url)\n",
    "\n",
    "\n",
    "    return urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_links(url):\n",
    "    edge_options = Options()\n",
    "    edge_options.add_argument('--headless')\n",
    "    edge_options.add_argument('--disable-gpu')\n",
    "    edge_options.add_argument('--no-sandbox') \n",
    "    \n",
    "    driver = webdriver.Edge(options=edge_options)\n",
    "    driver.get(url)\n",
    "\n",
    "    # Espera a que el botón de 'Accept all' esté presente y clicable\n",
    "    wait = WebDriverWait(driver, 10)  # Espera hasta 10 segundos\n",
    "    accept_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//span[text()='Aceptar todo']\")))\n",
    "\n",
    "    # Hace clic en el elemento <span>\n",
    "    accept_button.click()\n",
    "\n",
    "    # Esperar a que la nueva página comience a cargarse o hacer algo en el medio si es necesario\n",
    "    time.sleep(2)  # Pausa opcional para dar tiempo a la carga inicial de la página\n",
    "\n",
    "    # Scroll hacia abajo hasta el final de la página\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    while True:\n",
    "            # Desplazarse hacia abajo\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            \n",
    "            # Esperar a que se cargue la nueva sección\n",
    "            time.sleep(2)  # Ajusta el tiempo según sea necesario para la página\n",
    "            \n",
    "            # Calcular la nueva altura de la página después del scroll\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            \n",
    "            # Si la altura no cambia, hemos llegado al final de la página\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            \n",
    "            last_height = new_height\n",
    "\n",
    "    elements = driver.find_elements(By.CSS_SELECTOR, 'c-wiz[jsrenderer=\"ARwRbe\"]')\n",
    "\n",
    "    # Extraer los href de cada elemento si tienen un enlace dentro\n",
    "    links = []\n",
    "    for element in elements:\n",
    "        # Buscar el enlace dentro del elemento\n",
    "        link = element.find_element(By.TAG_NAME, 'a')\n",
    "        href = link.get_attribute('href')\n",
    "        if href:\n",
    "            links.append(href)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Encontrar todos los elementos <time> con class=\"hvbAAd\"\n",
    "    time_elements = driver.find_elements(By.CSS_SELECTOR, 'time.hvbAAd')\n",
    "\n",
    "    # Extraer el valor del atributo 'datetime' de cada <time>\n",
    "    datetimes = []\n",
    "    for element in time_elements:\n",
    "        datetime_value = element.get_attribute('datetime')\n",
    "        if datetime_value:\n",
    "            datetimes.append(datetime_value)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return links[1:], datetimes\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_parragraphs(url):\n",
    "    edge_options = Options()\n",
    "    edge_options.add_argument('--headless')\n",
    "\n",
    "    driver = webdriver.Edge(options=edge_options)\n",
    "    driver.get(url)\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Espera a que el botón de 'Accept all' esté presente y clicable\n",
    "        wait = WebDriverWait(driver, 10)  # Espera hasta 10 segundos\n",
    "        accept_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//span[text()='Accept all']\")))\n",
    "        \n",
    "        # Hace clic en el elemento <span>\n",
    "        accept_button.click()\n",
    "\n",
    "        # Esperar a que la nueva página comience a cargarse o hacer algo en el medio si es necesario\n",
    "        time.sleep(2)  # Pausa opcional para dar tiempo a la carga inicial de la página\n",
    "\n",
    "        # Scroll hacia abajo hasta el final de la página\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        \n",
    "        while True:\n",
    "            # Desplazarse hacia abajo\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            \n",
    "            # Esperar a que se cargue la nueva sección\n",
    "            time.sleep(2)  # Ajusta el tiempo según sea necesario para la página\n",
    "            \n",
    "            # Calcular la nueva altura de la página después del scroll\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            \n",
    "            # Si la altura no cambia, hemos llegado al final de la página\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            \n",
    "            last_height = new_height\n",
    "        \n",
    "        # Una vez que se ha llegado al final, obtener todos los párrafos <p>\n",
    "        paragraphs = driver.find_elements(By.TAG_NAME, 'p')\n",
    "        \n",
    "        # Imprimir el texto de cada párrafo\n",
    "        for paragraph in paragraphs:\n",
    "            return paragraph.text\n",
    "\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "        driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_urls = generate_urls(\"Vinicius Jr\", 2022, 1, 1, 2022, 6, 1)\n",
    "\n",
    "news_links_list = []\n",
    "news_datetimes_list = []\n",
    "\n",
    "for url in root_urls:\n",
    "    news_links, news_datetimes = get_news_links(url)\n",
    "    news_links_list.extend(news_links)\n",
    "    news_datetimes_list.extend(news_datetimes)\n",
    "\n",
    "list_paragraphs = []\n",
    "\n",
    "for news_links in news_links_list:\n",
    "    paragraph = get_news_parragraphs(news_links)\n",
    "    list_paragraphs.append(paragraph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
